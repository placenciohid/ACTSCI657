---
title: "In Class 2 - Dario Placencio"
output: html_document
date: "2023-02-22"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Consider data set PropertyFund.txt. The variable of interest is the loss amount, i.e. Claim. Take a subset of the data that contain observations with positive losses. The goal is to forecast the amount of losses for a government entity.

```{r}
# Read the data
rm(list=ls())
dat <- read.table("PropertyFund.txt", header = TRUE, sep = "", dec = ".")
dat.loss <- dat[which(dat$Claim>0),]

# Preview dat.loss
head(dat.loss)
```
```{r}
library("survival")
```

1. Perform Nelson Aalen estimation of the cumulative hazard function of loss amount. Plot the estimated cumulative hazard.

```{r}
# perform Nelson Aalen estimation of the cumulative hazard function
survObj <- Surv(dat.loss$Claim)
naEst <- survfit(survObj ~ 1, type = "fleming")
cumHazard <- -log(naEst$surv)
```

```{r}
# plot the estimated cumulative hazard function
plot(naEst$time, cumHazard, type = "l", xlab = "Time", ylab = "Cumulative Hazard", main = "Nelson Aalen Estimation of Cumulative Hazard Function")
```
The code above performs Nelson Aalen estimation of the cumulative hazard function using the Surv and survfit functions from the "survival" package. The estimated cumulative hazard function is then plotted using the plot function. The resulting plot should show a non-decreasing curve, indicating that the hazard of loss amount is increasing over time.

2. Evaluate the cumulative hazard at 100,000, and from which, estimate the survival function at 100,000. (Hint: relation between S(t) and H(t)).

```{r}
# Evaluate the cumulative hazard at 100,000
time_points <- naEst$time
cumHazard_points <- -log(naEst$surv)
hazard_at_100000 <- approx(x = time_points, y = cumHazard_points, xout = 100000)$y
hazard_at_100000
```

To estimate the survival function at 100,000, we can use the relationship between the cumulative hazard and the survival function
H(t) = -log(S(t))
Solving for S(t), we get
S(t) = exp(-H(t))

Therefore, we can estimate the survival function at 100,000 by taking the exponential of the negative of the cumulative hazard estimate at 100,000.

```{r}
# estimate the survival function at 100,000
surv_at_100000 <- exp(-hazard_at_100000)
surv_at_100000
```

3. Fit a Cox regression on the loss amount using entity type and logarithm of coverage as predictor. Report the estimated parameters. Plot the nonparametric estimates of the baseline cumulative hazard function.

```{r}
# fit a Cox regression on the loss amount using entity type and logarithm of coverage as predictors
cox_mod <- coxph(Surv(Claim) ~ EntityType + log(Coverage), data = dat.loss)

# report the estimated parameters
summary(cox_mod)
```

```{r}
# nonparametric estimates of the baseline cumulative hazard function
base_haz <- survfit(cox_mod, type = "fleming")

# plot the baseline cumulative hazard function
plot(base_haz, xlab = "Claim Amount", ylab = "Cumulative Hazard Function", main = "Nonparametric Estimate of Baseline Cumulative Hazard")
```
4. Consider the local government entity of the Madison School District. Assume that the logarithm of coverage amount (Coverage) is 500 (in thousand dollars). Use the cox regression in 3) to forecast the probability of an annual losses of greater than 100,000 dollars

```{r}
lambda <- base_haz$hazard[base_haz$time == 1]

# Define k as the number of covariates in the Cox model
k <- length(coef(cox_mod))

# Define H0func function
H0func <- function(t) {
  (1/k) * (log(1 + k*lambda*t) - (k*lambda*t)/(1 + k*lambda*t))
}

# Calculate probability of losses greater than 100,000 dollars
reg <- coefcox["factor(EntityType)School"] * 1 + coefcox["log(Coverage)"] * log(500)
reg <- as.numeric(reg)
St <- exp(-H0func(1)) ^ (exp(reg))
1 - St
```

