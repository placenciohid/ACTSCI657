<<<<<<< Updated upstream
knitr::opts_chunk$set(echo = TRUE)
# Likelihood ratio test with Anova
test_results <- anova(poisson_model, model_nb, test = "Chisq")
setwd("~/GitHub/ACTSCI657")
knitr::opts_chunk$set(echo = TRUE)
# Load the data
property_fund <- read.table("PropertyFund.txt", header = TRUE)
# Fit Poisson regression model with EntityType, AlarmCredit, and log of Coverage as predictors
poisson_model <- glm(Freq ~ EntityType + AlarmCredit + log(Coverage), data = property_fund, family = "poisson")
# View the summary of the model
summary(poisson_model)
# Calculate the residual deviance and degrees of freedom
resid_deviance <- sum(poisson_model$deviance)
df <- poisson_model$df.residual
# Calculate the dispersion parameter
dispersion <- resid_deviance / df
# Print results
cat("Residual deviance:", resid_deviance, "\n")
cat("Degrees of freedom:", df, "\n")
cat("Dispersion parameter:", dispersion, "\n")
library(MASS)
# Fit negative binomial model
model_nb <- glm.nb(Freq ~ EntityType + AlarmCredit + log(Coverage), data = property_fund)
# Print summary of results
summary(model_nb)
# Dispersion parameter
# Calculate the residual deviance and degrees of freedom
resid_deviance_nb <- sum(model_nb$deviance)
df_nb <- model_nb$df.residual
# Calculate the dispersion parameter
dispersion_nb <- resid_deviance_nb / df_nb
# Print results
cat("Residual deviance:", resid_deviance_nb, "\n")
cat("Degrees of freedom:", df_nb, "\n")
cat("Dispersion parameter:", dispersion_nb, "\n")
# Likelihood ratio test with Anova
test_results <- anova(poisson_model, model_nb, test = "Chisq")
# Extract p-value of likelihood ratio test
p_value <- test_results["Pr(>Chisq)"][2]
# Likelihood ratio test with Anova
test_results <- anova(poisson_model, model_nb, test = "Chisq")
# Extract p-value of likelihood ratio test
p_value <- test_results[2, "Pr(>Chisq)"]
p_value
# Likelihood ratio test with Anova
test_results <- anova(poisson_model, model_nb, test = "Chisq")
test_results
# Extract p-value of likelihood ratio test
# p_value <- test_results[2, "Pr(>Chisq)"]
# p_value
# Likelihood ratio test with Anova
test_results <- anova(poisson_model, model_nb, test = "Chisq")
# test_results
# Extract p-value of likelihood ratio test
p_value <- test_results[2, "Pr(>Chi)"]
p_value
# Likelihood ratio test with Anova
test_results <- anova(poisson_model, model_nb, test = "Chisq")
test_results
# Extract p-value of likelihood ratio test
p_value <- test_results[2, "Pr(>Chi)"]
p_value
# Likelihood ratio test with Anova
test_results <- anova(poisson_model, model_nb, test = "Chisq")
test_results
# Extract p-value of likelihood ratio test
p_value <- test_results["Pr(>Chi)"][2]
# Likelihood ratio test with Anova
test_results <- anova(poisson_model, model_nb, test = "Chisq")
test_results
# Likelihood ratio test with Anova
test_results <- anova(poisson_model, model_nb, test = "Chisq")$"Pr(>F)"
test_results
# Likelihood ratio test with Anova
test_results <- anova(poisson_model, model_nb, test = "Chisq")
test_results
View(test_results)
options(digits = 5)
# Likelihood ratio test with Anova
test_results <- anova(poisson_model, model_nb, test = "Chisq")
test_results
# Likelihood ratio test with Anova
test_results <- anova(poisson_model, model_nb, test = "Chisq")
test_results
# Likelihood ratio test with Anova
test_results <- anova(poisson_model, model_nb, test = "Chisq")
test_results
View(model_nb)
# Fit Poisson regression model with EntityType, AlarmCredit, and log of Coverage as predictors
poisson_model <- glm(Freq ~ EntityType + AlarmCredit + log(Coverage), data = property_fund, family = "quasipoisson")
# View the summary of the model
summary(poisson_model)
# Fit Poisson regression model with EntityType, AlarmCredit, and log of Coverage as predictors
poisson_model <- glm(Freq ~ EntityType + AlarmCredit + log(Coverage), data = property_fund, family = "poisson")
# View the summary of the model
summary(poisson_model)
# Fit Poisson regression model with EntityType, AlarmCredit, and log of Coverage as predictors
poisson_model <- glm(Freq ~ EntityType + AlarmCredit + log(Coverage), data = property_fund, family = "quasipoisson")
# View the summary of the model
summary(poisson_model)
mds_data <- subset(property_fund, EntityType == School & Coverage == 100 & AlarmCredit == AC10%)
mds_data <- subset(property_fund, EntityType == 'School' & Coverage == 100 & AlarmCredit == 'AC10%')
View(mds_data)
View(model_nb)
# Predict expected number of claims from Poisson model
poisson_preds <- predict(poisson_model, newdata = data.frame((EntityType == "School", AlarmCredit == "AC10%", Coverage == 100), type = "response")
# Predict expected number of claims from Poisson model
poisson_preds <- predict(poisson_model, newdata = data.frame(EntityType == "School" & AlarmCredit == "AC10%" & Coverage == 100), type = "response")
# Predict expected number of claims from Poisson model
poisson_preds <- predict(poisson_model, newdata = data.frame(EntityType == "School" & AlarmCredit == "AC10%" & Coverage == 100), type = "response")
# Predict expected number of claims from Poisson model
poisson_preds <- predict(poisson_model, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage == 100), type = "response")
# Predict expected number of claims from Poisson model
poisson_preds <- predict(poisson_model, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage = 100), type = "response")
# Predict expected number of claims from Negative Binomial model
#negbin_preds <- predict(negbin_model, newdata = data.frame(exposure = 100, alarm = 1.1), type = "response")
# Predict expected number of claims from Poisson model
poisson_preds <- predict(poisson_model, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage = 100, type = "response")
# Predict expected number of claims from Negative Binomial model
nb_preds <- predict(model_nb, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage = 100, type = "response)
# Predict expected number of claims from Poisson model
poisson_preds <- predict(poisson_model, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage = 100, type = "response")
# Predict expected number of claims from Negative Binomial model
nb_preds <- predict(model_nb, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage = 100, type = "response)
# Predict expected number of claims from Poisson model
poisson_preds <- predict(poisson_model, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage = 100, type = "response")
# Predict expected number of claims from Negative Binomial model
nb_preds <- predict(model_nb, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage = 100, type = "response)
# Predict expected number of claims from Poisson model
poisson_preds <- predict(poisson_model, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage = 100, type = "response")
# Predict expected number of claims from Negative Binomial model
nb_preds <- predict(model_nb, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage = 100, type = "response")
# Predict expected number of claims from Poisson model
poisson_preds <- predict(poisson_model, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage = 100, type = "response")
# Predict expected number of claims from Negative Binomial model
nb_preds <- predict(model_nb, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage = 100, type = "response")
# Predict expected number of claims from Poisson model
poisson_preds <- predict(poisson_model, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage = 100, type = "response")
# Predict expected number of claims from Poisson model
poisson_preds <- predict(poisson_model, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage = 100), type = "response")
# Predict expected number of claims from Poisson model
poisson_preds <- predict(poisson_model, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage = 100), type = "response")
# Predict expected number of claims from Negative Binomial model
nb_preds <- predict(model_nb, newdata = data.frame(EntityType = "School", AlarmCredit = "AC10%", Coverage = 100), type = "response")
# Print predicted expected number of claims from Poisson model
poisson_preds
# Print predicted expected number of claims from Negative Binomial model
nb_preds
# Calculate predicted probability for Poisson model
poisson_prob <- 1 - ppois(5, lambda=poisson_preds)
poisson_prob
# Calculate predicted probability for Negative Binomial model
nb_prob <- 1 - pnbinom(5, size=nb_fit$theta, mu=nb_preds)
# Calculate predicted probability for Poisson model
poisson_prob <- 1 - ppois(5, lambda=poisson_preds)
poisson_prob
# Calculate predicted probability for Negative Binomial model
nb_prob <- 1 - pnbinom(5, size=model_nb$theta, mu=nb_preds)
nb_prob
=======
weib_cumhaz <- cumsum(weib_haz$hazard) * weib_haz$interval
# Plot Cox and Weibull cumulative baseline hazard
plot(cox_haz$Time, cox_cumhaz, type = "l", xlab = "Time", ylab = "Cumulative Baseline Hazard", col = "blue")
# Fit Weibull regression
weib_mod <- survreg(Surv(Claim, Freq) ~ log(Coverage) + EntityType, data = dat.loss, dist = "weibull")
# Estimate cumulative base hazard function for Weibull regression
weib_haz <- basehaz(cox_mod, centered = TRUE)
weib_cumhaz <- cumsum(weib_haz$hazard) * weib_haz$interval
# Plot Cox and Weibull cumulative baseline hazard
plot(weib_haz$time, weib_cumhaz, type = "l", xlab = "Time", ylab = "Cumulative Baseline Hazard", col = "red")
# Fit Weibull regression
weib_mod <- survreg(Surv(Claim, Freq) ~ log(Coverage) + EntityType, data = dat.loss, dist = "weibull")
# Estimate cumulative base hazard function for Weibull regression
weib_haz <- basehaz(cox_mod, centered = TRUE)
weib_cumhaz <- cumsum(weib_haz$hazard) * weib_haz$interval
# estimate cumulative base hazard function for Cox regression
cox_base_haz <- basehaz(cox_mod)
# estimate cumulative base hazard function for Weibull regression
weib_base_haz <- survfit(weib_mod, type = "fh")
# estimate cumulative base hazard function for Cox regression
cox_base_haz <- basehaz(cox_mod)
# estimate cumulative base hazard function for Weibull regression
weib_base_haz <- survfit(weib_mod, type = "fleming")
# Plot both hazards
plot(cox_base_haz, col = "blue", lwd = 2, main = "Comparison of Cumulative Hazards", xlab = "Time", ylab = "Cumulative Hazard")
curve(weib_haz, add = TRUE, col = "red", lwd = 2, lty = 2)
# Plot both hazards
plot(cox_base_haz, col = "blue", lwd = 2, main = "Comparison of Cumulative Hazards", xlab = "Time", ylab = "Cumulative Hazard")
curve(weib_haz, add = TRUE, col = "red", lwd = 2, lty = 2)
View(weib_haz)
# Plot both hazards
plot(cox_base_haz, col = "blue", lwd = 2, main = "Comparison of Cumulative Hazards", xlab = "Time", ylab = "Cumulative Hazard")
curve(weib_haz, add = TRUE, col = "red", lwd = 2, lty = 2)
# Plot both hazards
plot(cox_base_haz, col = "blue", lwd = 2, main = "Comparison of Cumulative Hazards", xlab = "Time", ylab = "Cumulative Hazard")
plot(weib_haz, add = TRUE, col = "red", lwd = 2, lty = 2)
legend("topright", legend = c("Cox", "Weibull"), lty = c(1, 2), col = c("blue", "red"), lwd = 2)
# Plot both hazards
plot(cox_base_haz, col = "blue", lwd = 2, main = "Comparison of Cumulative Hazards", xlab = "Time", ylab = "Cumulative Hazard")
curve(weib_haz, add = TRUE, col = "red", lwd = 2, lty = 2)
# Plot both hazards
plot(cox_base_haz, col = "blue", lwd = 2, main = "Comparison of Cumulative Hazards", xlab = "Time", ylab = "Cumulative Hazard")
curve(weib_cumhaz, add = TRUE, col = "red", lwd = 2, lty = 2)
knitr::opts_chunk$set(echo = TRUE)
# Define the observed and predicted values
observed <- c(5, 2, 4, 0, 1)
predicted <- c(6, 1, 2, 3, 2)
# Define functions for each scoring function
se <- function(obs, pred) (pred - obs)^2
ae <- function(obs, pred) abs(pred - obs)
ape <- function(obs, pred) 100 * abs(pred - obs) / obs
re <- function(obs, pred) abs((pred - obs) / obs)
# Calculate the score functions for each observation
se_scores <- se(observed, predicted)
ae_scores <- ae(observed, predicted)
ape_scores <- ape(observed, predicted)
re_scores <- re(observed, predicted)
# Calculate the average score functions
mean(se_scores)
mean(ae_scores)
mean(ape_scores, na.rm = TRUE)
mean(re_scores, na.rm = TRUE)
# Define the observed and predicted values
observed <- c(5, 2, 4, 0, 1)
predicted <- c(6, 1, 2, 3, 2)
# Define functions for each scoring function
se <- function(obs, pred) (pred - obs)^2
ae <- function(obs, pred) abs(pred - obs)
ape <- function(obs, pred) ifelse(obs == 0, NA, 100 * abs(pred - obs) / obs)
re <- function(obs, pred) ifelse(obs == 0, NA, abs((pred - obs) / obs))
# Calculate the score functions for each observation
se_scores <- se(observed, predicted)
ae_scores <- ae(observed, predicted)
ape_scores <- ape(observed, predicted)
re_scores <- re(observed, predicted)
# Calculate the average score functions
mean(se_scores)
mean(ae_scores)
mean(ape_scores, na.rm = TRUE)
mean(re_scores, na.rm = TRUE)
# Set sample size
n <- 500
# Set true parameter values
beta0 <- 1.2
beta1 <- 0.01
beta2 <- 0.4
# Create predictor variables
x1 <- rnorm(n, mean = 40, sd = sqrt(15))
x2 <- rbinom(n, size = 1, prob = 0.2)
# Create outcome variable
lambda <- exp(beta0 + beta1*x1 + beta2*x2)
y <- rpois(n, lambda)
# View summary statistics of data
summary(data.frame(y, x1, x2))
# Fit Poisson regression model
model <- glm(y ~ x1 + x2, data = data, family = "poisson")
# Set sample size
n <- 500
# Set true parameter values
beta0 <- 1.2
beta1 <- 0.01
beta2 <- 0.4
# Create predictor variables
x1 <- rnorm(n, mean = 40, sd = sqrt(15))
x2 <- rbinom(n, size = 1, prob = 0.2)
# Create outcome variable
lambda <- exp(beta0 + beta1*x1 + beta2*x2)
y <- rpois(n, lambda)
# Store the data
data <- data.frame(y, x1, x2))
# Set sample size
n <- 500
# Set true parameter values
beta0 <- 1.2
beta1 <- 0.01
beta2 <- 0.4
# Create predictor variables
x1 <- rnorm(n, mean = 40, sd = sqrt(15))
x2 <- rbinom(n, size = 1, prob = 0.2)
# Create outcome variable
lambda <- exp(beta0 + beta1*x1 + beta2*x2)
y <- rpois(n, lambda)
# Store the data
my_data <- data.frame(y = y, x1 = x1, x2 = x2)
# View summary statistics of data
summary(my_data)
# Fit Poisson regression model
model <- glm(y ~ x1 + x2, data = my_data, family = "poisson")
# View summary of model results
summary(model)
# Create predictor variables for a 50-year old male smoker
x1 <- 50
x2 <- 1
# Predict expected number of ER visits using the fitted model
lambda <- exp(predict(fit, newdata = data.frame(x1, x2)))
# Create predictor variables for a 50-year old male smoker
x1 <- 50
x2 <- 1
# Predict expected number of ER visits using the fitted model
lambda <- exp(predict(model, newdata = data.frame(x1, x2)))
# Calculate the probability of having 0 ER visits
prob <- dpois(0, lambda)
# Print the probability
cat("The likelihood of having no ER visits for a 50-year old male smoker is", prob)
# Fit Poisson regression model
model <- glm(y ~ x1 + x2, family = "poisson", data = my_data)
# Calculate predicted values
pred <- predict(model, type = "response")
# Calculate proportion of predicted values equal to zero
prop_zero <- mean(pred == 0)
# Compare to observed proportion of zero ER visits
obs_prop_zero <- 120/500
# Perform chi-squared test of goodness-of-fit
chisq.test(c(prop_zero, 1-prop_zero), p = c(obs_prop_zero, 1-obs_prop_zero))
# Parameters
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Hazard function
hazard <- function(x1, x2, t) {
lambda <- alpha * exp(beta1 * x1 + beta2 * x2)
hazard <- lambda * exp(-lambda * t)
return(hazard)
}
# Calculate hazard at t=1 year for a 50-year old male smoker (x1=50, x2=1)
hazard(50, 1, 1)
# Fit the hazard regression model
library(survival)
data <- read.csv("er_data.csv")
# Define the hazard function
hazard_func <- function(age, smoker, alpha, beta1, beta2) {
exp(beta1 * age + beta2 * smoker) * alpha
}
# Define the survival function
survival_func <- function(age, smoker, alpha, beta1, beta2, expenditure) {
exp(-integrate(hazard_func, 0, expenditure, age = age, smoker = smoker, alpha = alpha, beta1 = beta1, beta2 = beta2)$value)
}
# Define the parameters of the model
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Calculate the likelihood of exceeding $1,000 in expenditure
1 - survival_func(age = 50, smoker = 1, alpha = alpha, beta1 = beta1, beta2 = beta2, expenditure = 1000)
# Define the hazard function
hazard_func <- function(expenditure, x1, x2, alpha, beta1, beta2) {
exp(beta1 * x1 + beta2 * x2) * alpha
}
# Define the survival function
survival_func <- function(expenditure, x1, x2, alpha, beta1, beta2) {
exp(-integrate(hazard_func, 0, expenditure, x1 = x1, x2 = x2, alpha = alpha, beta1 = beta1, beta2 = beta2)$value)
}
# Define the parameters of the model
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Calculate the likelihood of exceeding $1,000 in expenditure
1 - survival_func(x1 = 50, x2 = 1, alpha = alpha, beta1 = beta1, beta2 = beta2, expenditure = 1000)
# Define the hazard function
hazard_func <- function(x1, x2, alpha, beta1, beta2) {
print(x1)
print(x2)
print(alpha)
print(beta1)
print(beta2)
exp(beta1 * x1 + beta2 * x2) * alpha
}
# Define the survival function
survival_func <- function(x1, x2, alpha, beta1, beta2, expenditure) {
print(x1)
print(x2)
print(alpha)
print(beta1)
print(beta2)
print(expenditure)
exp(-integrate(hazard_func, 0, expenditure, x1 = x1, x2 = x2, alpha = alpha, beta1 = beta1, beta2 = beta2)$value)
}
# Define the parameters of the model
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Calculate the likelihood of exceeding $1,000 in expenditure
1 - survival_func(x1 = 50, x2 = 1, alpha = alpha, beta1 = beta1, beta2 = beta2, expenditure = 1000)
# Define the hazard function
hazard_func <- function(age, smoker, alpha, beta1, beta2) {
exp(beta1 * age + beta2 * smoker) * alpha
}
# Define the survival function
survival_func <- function(age, smoker, alpha, beta1, beta2, expenditure) {
exp(-integrate(hazard_func, 0, expenditure, age = age, smoker = smoker, alpha = alpha, beta1 = beta1, beta2 = beta2)$value)
}
# Define the parameters of the model
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Calculate the likelihood of exceeding $1,000 in expenditure
1 - survival_func(age = 50, smoker = 1, alpha = alpha, beta1 = beta1, beta2 = beta2, expenditure = 1000)
# Define the hazard function
hazard_func <- function(age, smoker, alpha, beta1, beta2) {
exp(beta1 * age + beta2 * smoker) * alpha
}
# Define the survival function
survival_func <- function(age, smoker, alpha, beta1, beta2, expenditure) {
exp(-integrate(hazard_func, 0, expenditure, age = age, smoker = smoker, alpha = alpha, beta1 = beta1, beta2 = beta2)$value)
}
# Define the parameters of the model
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Calculate the likelihood of exceeding $1,000 in expenditure
1 - survival_func(age = 50, smoker = 1, alpha = alpha, beta1 = beta1, beta2 = beta2, expenditure = 1000)
# Define the parameters of the model
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Calculate the likelihood of exceeding $1,000 in expenditure
1 - survival_func(age = 50, smoker = 1, alpha = alpha, beta1 = beta1, beta2 = beta2, expenditure = 1000)
# Define the hazard function
hazard_func <- function(age, smoker, alpha, beta1, beta2) {
exp(beta1 * age + beta2 * smoker) * alpha
}
# Define the survival function
survival_func <- function(age, smoker, alpha, beta1, beta2, expenditure) {
exp(-integrate(hazard_func, 0, expenditure, age = age, smoker = smoker, alpha = alpha, beta1 = beta1, beta2 = beta2)$value)
}
# Define the parameters of the model
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Calculate the likelihood of exceeding $1,000 in expenditure
1 - survival_func(age = 50, smoker = 1, alpha = alpha, beta1 = beta1, beta2 = beta2, expenditure = 1000)
# Define the hazard function
hazard_func <- function(age, smoker, alpha, beta1, beta2) {
exp(beta1 * age + beta2 * smoker) * alpha
}
# Define the survival function
survival_func <- function(age, smoker, alpha, beta1, beta2, expenditure) {
exp(-integrate(hazard_func, 0, expenditure, age = age, smoker = smoker, alpha = alpha, beta1 = beta1, beta2 = beta2)$value)
}
# Define the parameters of the model
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Calculate the likelihood of exceeding $1,000 in expenditure
1 - survival_func(age = 50, smoker = 1, alpha = alpha, beta1 = beta1, beta2 = beta2, expenditure = 1000)
# Parameters
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Probability of exceeding $1000 in a year
survival <- function(x1, x2, t) {
lambda <- alpha * exp(beta1 * x1 + beta2 * x2)
survival <- exp(-lambda * t)
return(survival)
}
1 - survival(50, 1, 1_000)
# Parameters
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Probability of exceeding $1000 in a year
survival <- function(x1, x2, t) {
lambda <- alpha * exp(beta1 * x1 + beta2 * x2)
survival <- exp(-lambda * t)
return(survival)
}
1 - survival(50, 1, 1_000)
# Parameters
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Probability of exceeding $1000 in a year
survival <- function(x1, x2, t) {
lambda <- alpha * exp(beta1 * x1 + beta2 * x2)
survival <- exp(-lambda * t)
return(survival)
}
1 - survival(50, 1, 1_000)
# Parameters
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Probability of exceeding $1000 in a year
survival <- function(x1, x2, t) {
lambda <- alpha * exp(beta1 * x1 + beta2 * x2)
survival <- exp(-lambda * t)
return(survival)
}
1 - survival(50, 1, 1_000)
1 - survival(50, 1, 1000)
# Parameters
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Probability of exceeding $1000 in a year
survival <- function(x1, x2, t) {
lambda <- alpha * exp(beta1 * x1 + beta2 * x2)
survival <- exp(-lambda * t)
return(survival)
}
1 - survival(50, 1, 1000)
# Parameters
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Probability of exceeding $1000 in a year
survival <- function(x1, x2, t) {
lambda <- alpha * exp(beta1 * x1 + beta2 * x2)
survival <- exp(-lambda * t)
return(survival)
}
1 - survival(50, 1, 1000)
# Parameters
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Probability of exceeding $1000 in a year
survival <- function(x1, x2, t) {
lambda <- alpha * exp(beta1 * x1 + beta2 * x2)
survival <- exp(-lambda * t)
return(survival)
}
1 - survival(50, 1, 1000)
# Parameters
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Probability of exceeding $1000 in a year
survival <- function(x1, x2, t) {
lambda <- alpha * exp(beta1 * x1 + beta2 * x2)
survival <- exp(-lambda * t)
return(survival)
}
1 - survival(50, 1, 1000)
# Parameters
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Probability of exceeding $1000 in a year
survival <- function(x1, x2, t) {
lambda <- alpha * exp(beta1 * x1 + beta2 * x2)
survival <- exp(-lambda * t)
return(survival)
}
1 - survival(50, 1, 1000)
# Parameters
alpha <- 0.01
beta1 <- -0.05
beta2 <- 0.75
# Probability of exceeding $1000 in a year
survival <- function(x1, x2, t) {
lambda <- alpha * exp(beta1 * x1 + beta2 * x2)
survival <- exp(-lambda * t)
return(survival)
}
1 - survival(50, 1, 1000)
setwd("~/GitHub/ACTSCI657")
knitr::opts_chunk$set(echo = TRUE)
# Load the data
rm(list=ls())
data <- read.table(file='HailRisk.txt', header = TRUE, sep = "", dec = ".")
# Create risk classes based on SingleFamily and ShingleRoof variables
risk_classes <- paste0("SF", data$SingleFamily, "_SR", data$ShingleRoof)
# Count the number of unique risk classes
n_classes <- length(unique(risk_classes))
# Print the number of risk classes and their definitions
cat("The insurer uses", n_classes, "risk classes:\n")
cat(unique(risk_classes))
install.packages("statmod")
install.packages("tweedie")
install.packages("dplyr")
remove.packages("rlang")
install.packages("rlang")
library(rlang)
library(dplyr)
library(rlang)
library(statmod)
library(tweedie)
library(dplyr)
library(statmod)
fit1 <- glm(paidloss~ SingleFamily + ShingleRoof, offset = log(BLDG_LMT),
family=tweedie(var.power=1.5,link.power=0), data=data)
summary(fit1)
# Calculate the rate for each risk class based on the fitted model
# Calculate the rate for each observation
rates <- exp(fit1$coefficients[1] +
fit1$coefficients[2] * data$SingleFamily +
fit1$coefficients[3] * data$ShingleRoof) / data$BLDG_LMT
# Aggregate the rates by risk class
aggregate(rates, by = list(risk_classes), FUN = mean)
# Calculate expected paid loss for each observation
data$expected_paidloss <- predict(fit1, type = "response", offset = log(data$BLDG_LMT))
# Calculate rate for each observation
data$rate <- data$expected_paidloss / data$BLDG_LMT
# Calculate average rate for each risk class
avg_rate <- data %>%
group_by(risk_classes) %>%
summarise(avg_rate = mean(rate))
# Calculate expected paid loss for each observation
data$expected_paidloss <- predict(fit1, type = "response", offset = log(data$BLDG_LMT))
# Calculate rate for each observation
data$rate <- data$expected_paidloss / data$BLDG_LMT
risk_classes <- data.fram(paste0("SF", data$SingleFamily, "_SR", data$ShingleRoof))
# Calculate expected paid loss for each observation
data$expected_paidloss <- predict(fit1, type = "response", offset = log(data$BLDG_LMT))
# Calculate rate for each observation
data$rate <- data$expected_paidloss / data$BLDG_LMT
risk_classes <- data.frame(paste0("SF", data$SingleFamily, "_SR", data$ShingleRoof))
# Calculate average rate for each risk class
avg_rate <- data %>%
group_by(risk_classes) %>%
summarise(avg_rate = mean(rate))
View(risk_classes)
View(risk_classes)
# Fit a new Tweedie GLM model with interaction
fit2 <- glm(paidloss ~ SingleFamily * ShingleRoof, offset = log(BLDG_LMT),
family = tweedie(var.power = 1.5, link.power = 0), data = dat)
# Fit a new Tweedie GLM model with interaction
fit2 <- glm(paidloss ~ SingleFamily * ShingleRoof, offset = log(BLDG_LMT),
family = tweedie(var.power = 1.5, link.power = 0), data = data)
summary(fit2)
# Calculate the rate for each observation
rates2 <- exp(fit2$coefficients[1] +
fit2$coefficients[2] * dat$SingleFamily +
fit2$coefficients[3] * dat$ShingleRoof +
fit2$coefficients[4] * dat$SingleFamily * dat$ShingleRoof) / dat$BLDG_LMT
# Calculate the rate for each observation
rates2 <- exp(fit2$coefficients[1] +
fit2$coefficients[2] * data$SingleFamily +
fit2$coefficients[3] * data$ShingleRoof +
fit2$coefficients[4] * data$SingleFamily * data$ShingleRoof) / data$BLDG_LMT
# Aggregate the rates by risk class
aggregate(rates2, by = list(risk_classes), FUN = mean)
knitr::opts_chunk$set(echo = TRUE)
# Load the data
rm(list=ls())
data <- read.table(file='HailRisk.txt', header = TRUE, sep = "", dec = ".")
# Create risk classes based on SingleFamily and ShingleRoof variables
risk_classes <- paste0("SF", data$SingleFamily, "_SR", data$ShingleRoof)
# Count the number of unique risk classes
n_classes <- length(unique(risk_classes))
# Print the number of risk classes and their definitions
cat("The insurer uses", n_classes, "risk classes:\n")
cat(unique(risk_classes))
library(rlang)
library(statmod)
library(tweedie)
library(dplyr)
library(statmod)
fit1 <- glm(paidloss~ SingleFamily + ShingleRoof, offset = log(BLDG_LMT),
family=tweedie(var.power=1.5,link.power=0), data=data)
summary(fit1)
# Calculate the rate for each risk class based on the fitted model
# Calculate the rate for each observation
rates <- exp(fit1$coefficients[1] +
fit1$coefficients[2] * data$SingleFamily +
fit1$coefficients[3] * data$ShingleRoof) / data$BLDG_LMT
# Aggregate the rates by risk class
aggregate(rates, by = list(risk_classes), FUN = mean)
# Fit a new Tweedie GLM model with interaction
fit2 <- glm(paidloss ~ SingleFamily * ShingleRoof, offset = log(BLDG_LMT),
family = tweedie(var.power = 1.5, link.power = 0), data = data)
summary(fit2)
# Calculate the rate for each observation
rates2 <- exp(fit2$coefficients[1] +
fit2$coefficients[2] * data$SingleFamily +
fit2$coefficients[3] * data$ShingleRoof +
fit2$coefficients[4] * data$SingleFamily * data$ShingleRoof) / data$BLDG_LMT
# Aggregate the rates by risk class
aggregate(rates2, by = list(risk_classes), FUN = mean)
View(fit1)
View(fit1)
View(fit1)
>>>>>>> Stashed changes
